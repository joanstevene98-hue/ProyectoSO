\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{xfrac}
\usepackage{tipa}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Simulador de Mini-Kernel: Arquitectura, Implementación y Análisis Exhaustivo de Políticas de Sistemas Operativos}

\author{\IEEEauthorblockN{Equipo de Desarrollo}
\IEEEauthorblockA{\textit{Ingeniería de Sistemas} \\
\textit{Universidad Distrital Francisco José de Caldas}\\
Bogotá, Colombia \\
}
}

\maketitle

\begin{abstract}

\noindent Este informe presenta una documentación exhaustiva y detallada del desarrollo del simulador "Mini-Kernel", un proyecto integral diseñado específicamente para facilitar la comprensión profunda, experimentación controlada y evaluación rigurosa de conceptos fundamentales de sistemas operativos mediante una simulación de entorno de ejecución controlado en ambiente académico. El documento expone de manera pormenorizada la motivación pedagógica detrás del proyecto, la arquitectura hexagonal adoptada como patrón de diseño arquitectónico, las decisiones críticas y justificadas de diseño, los algoritmos específicos implementados para cada subsistema, los detalles técnicos de implementación a nivel de código fuente, la estrategia comprehensiva y multi-nivel de pruebas y validación, así como observaciones detalladas surgidas durante el desarrollo. El simulador integra de manera cohesiva cuatro subsistemas principales: un planificador de procesos basado en Round Robin con quantum configurable, un gestor de memoria contigua basado en First Fit con coalescencia automática, un sistema de archivos en memoria con asignación contigua de bloques, y un modelo de dispositivos de entrada/salida con colas FIFO independientes. La arquitectura hexagonal utilizada permite la separación clara y completa entre lógica de dominio e implementaciones concretas de adaptadores, facilitando tanto el testing unitario e integración como la extensibilidad futura del sistema. Este proyecto constituye una base sólida y documentada para actividades académicas, de investigación aplicada y de experimentación comparativa en el área de sistemas operativos.

\end{abstract}

\begin{IEEEkeywords}
Mini-kernel, simulador de sistemas operativos, Round Robin, First Fit, asignación de memoria, sistema de archivos, entrada/salida, arquitectura hexagonal, ports and adapters, scheduling, memory management, pedagogía en sistemas operativos
\end{IEEEkeywords}

\section{INTRODUCCIÓN}

\IEEEPARstart{L}{a} enseñanza de sistemas operativos en programas de ingeniería informática y de sistemas representa uno de los desafíos pedagógicos más significativos en la educación en computación. Los conceptos fundamentales como planificación de procesos, gestión de memoria, organización de sistemas de archivos y manejo de dispositivos de entrada/salida constituyen la piedra angular del conocimiento informático moderno. Sin embargo, su complejidad inherente y su naturaleza altamente interconectada presentan dificultades sustanciales para la enseñanza efectiva en ambientes académicos.

En la práctica real de sistemas operativos contemporáneos, estos conceptos se encuentran íntimamente relacionados entre sí de manera orgánica y compleja. Una decisión de diseño en planificación impacta directamente el comportamiento de la memoria y su fragmentación. Las operaciones de entrada/salida afectan las decisiones de scheduling porque los procesos se bloquean esperando dispositivos. La estructura del sistema de archivos influye en el rendimiento global. Sin embargo, en la enseñanza tradicional estos subsistemas se presentan aislados en capítulos independientes. Estudiantes aprenden Round Robin, First Fit y FIFO en abstracto, pero raramente experimentan cómo estos algoritmos interactúan cuando funcionan simultáneamente en un sistema integrado. Esta separación entre teoría y práctica crea una brecha pedagógica significativa: existe diferencia sustancial entre entender "qué es" un concepto y comprender "cómo se comporta cuando interactúa con otros componentes".

Adicionalmente, existe escasez notoria de herramientas educativas de código abierto que permitan experimentación controlada con políticas de sistemas operativos. Aunque existen simuladores comerciales, la mayoría de programas académicos carecen de herramientas que sean simultáneamente accesibles, extensibles y pedagógicamente valiosas. Muchas herramientas existentes son demasiado complejas, oscureciendo conceptos fundamentales bajo implementación detallada. Otras son excesivamente simplificadas y no capturan comportamientos importantes. Pocas ofrecen equilibrio entre claridad conceptual y fidelidad suficiente para observar fenómenos relevantes de sistemas operativos reales.

El objetivo principal de este proyecto es ofrecer un entorno didáctico altamente controlable, reproducible y extensible que permita a estudiantes e investigadores entender profundamente cómo interactúan los distintos subsistemas de un kernel de sistema operativo. Este simulador está diseñado como plataforma de experimentación donde estudiantes pueden variar parámetros, ejecutar escenarios complejos y observar cuantitativamente las consecuencias de decisiones de diseño. Los objetivos específicos incluyen: crear un entorno simulado donde cuatro subsistemas principales interactúan de manera realista; proporcionar herramientas de visualización que permitan observar el estado del sistema en tiempo real; implementar arquitectura extensible que permita cambiar políticas sin impactar otros componentes; desarrollar suite comprehensiva de tests que valide correctitud; y crear documentación extensiva que facilite reproducción de experimentos.

El simulador integra múltiples módulos funcionales que interactúan dinámicamente: planificador Round Robin con quantum configurable, gestor de memoria First Fit con coalescencia automática, sistema de archivos con asignación contigua, y dispositivos de E/S con colas FIFO. Estos componentes no funcionan en aislamiento sino que interactúan de maneras complejas. Un quantum pequeño afecta fragmentación de memoria porque incrementa cambios de contexto. Saturación en colas de E/S afecta métricas de scheduling porque procesos se bloquean esperando dispositivos. Esta integración permite que estudiantes observen efectos transversales imposibles de capturar en enseñanza modular.

Desde perspectiva pedagógica, el simulador responde a necesidad crítica de visualizar dinámicamente el estado del sistema operativo durante ejecución. Visualización permite observación directa de colas de procesos en distintos estados (New, Ready, Running, Blocked, Terminated), mapas de memoria mostrando fragmentación en tiempo real, estructuras de archivos con fragmentación progresiva, y colas de dispositivos afectando tiempos de respuesta. El simulador genera trazas y métricas cuantificables (turnaround promedio, tiempos de respuesta, fragmentación como porcentaje, cambios de contexto, latencias) que permiten análisis estadístico riguroso y estudios comparativos de políticas diferentes bajo condiciones reproducibles.

El proyecto está diseñado con arquitectura extensible de nivel profesional, permitiendo que desarrolladores futuros agreguen nuevas políticas y algoritmos sin modificar el núcleo del sistema. Esta característica lo hace valioso tanto para docencia introductoria como para investigación aplicada. La arquitectura está diseñada para evolución gradual, permitiendo que el simulador crezca con necesidades de un programa académico.

El resto de este informe está organizado como sigue. La sección de Arquitectura describe el patrón hexagonal adoptado. La sección de Algoritmos documenta decisiones sobre políticas implementadas en cada subsistema. Secciones posteriores cubren estructuras de datos, implementación, estrategia de pruebas, resultados experimentales, limitaciones, extensiones futuras, guía de compilación, y conclusiones. El objetivo es proporcionar documentación exhaustiva que permita tanto reproducción del trabajo como su extensión con nuevas características.



\section{Arquitectura del Simulador: Patrón Hexagonal (Ports and Adapters)}

La arquitectura adoptada para este proyecto es la arquitectura hexagonal, también conocida como el patrón Ports and Adapters, propuesto inicialmente por Alistair Cockburn en 2005. Esta arquitectura propone una separación clara, completa y disciplinada entre el núcleo de dominio (domain core), que contiene la lógica y las reglas del negocio o del problema, y las implementaciones externas concretas que interactúan con él. En el contexto específico de un simulador de kernel, el núcleo de dominio encapsula las reglas de planificación de procesos, los invariantes de la memoria, la semántica básica del sistema de archivos y el comportamiento lógico de las operaciones de entrada/salida.

La elección de arquitectura hexagonal respondió a múltiples necesidades concretas y técnicas identificadas durante el análisis de requisitos. Primero, facilitó el aislamiento del dominio para realizar pruebas unitarias de manera rigurosa sin depender de la entrada/salida real o de infraestructura externa compleja. Segundo, permitió cambiar implementaciones concretas sin necesidad de modificar la lógica central del dominio: por ejemplo, se puede cambiar la implementación de un algoritmo de planificación de Round Robin a Priority Scheduling sin tocar el resto del código o las pruebas de integración existentes. Tercero, la arquitectura ayuda directamente a la escalabilidad y extensibilidad: la integración de nuevas características (por ejemplo, soporte para paginación de memoria, segmentación o gestión de memoria virtual) puede implementarse como adaptadores que se conectan al puerto correspondiente sin disrupción a las capas superiores o a otros componentes.

En el repositorio git, esta arquitectura se refleja de manera muy clara en la organización jerárquica de carpetas del proyecto:

\begin{itemize}
\item \texttt{domain/} contiene las entidades fundamentales del dominio (PCB, MemoryBlock, FCB, etc.) y los puertos que definen los contratos que deben ser implementados.
\item \texttt{application/} contiene los casos de uso que coordinan operaciones del núcleo y orquestan los componentes de manera coherente.
\item \texttt{adapters/outbound/} contiene implementaciones concretas de los puertos: planificadores específicos, gestor de memoria, sistema de archivos, dispositivos.
\item \texttt{adapters/inbound/} contiene runners y CLI (command-line interfaces) que permiten ejecutar demostraciones y escenarios de integración desde la línea de comandos.
\end{itemize}

Esta organización no es puramente estética o cosmética; tiene implicaciones directas en la mantenibilidad, la escalabilidad y el desarrollo colaborativo del código. La separación entre puertos y adaptadores tiene implicaciones muy concretas en la implementación: los puertos definen interfaces en C++ que son clases abstractas puras, especificando contratos con métodos y comportamientos esperados. Los adaptadores concretos implementan estas interfaces de manera específica. En las pruebas unitarias, los puertos se pueden sustituir por stubs o dobles de prueba que permiten aislar la lógica bajo prueba sin depender de implementaciones concretas potencialmente complejas. Esta forma de trabajo disciplinada mejora significativamente la robustez, la fiabilidad y la mantenibilidad del desarrollo.

A nivel conceptual y práctico, la arquitectura hexagonal también favorece la reproducibilidad de experimentos: un mismo caso de uso puede ejecutarse con distintos adaptadores conservando la semántica del dominio intacta. Esto es particularmente útil para comparar distintos algoritmos (por ejemplo, First Fit vs Best Fit vs Buddy Allocator) bajo igualdad de condiciones experimentales.

\section{Algoritmos Implementados y Decisiones de Diseño Justificadas}

En esta sección se documentan de manera minuciosa las decisiones sobre las políticas algorítmicas implementadas en cada subsistema principal del simulador. Estas decisiones fueron guiadas explícitamente por criterios pedagógicos (claridad de presentación y capacidad de ilustrar fenómenos esenciales) y por la simplicidad de implementación y verificación, evitando complejidad innecesaria que distraería de los objetivos educativos.

\subsection{Planificación de Procesos: Round Robin}

La planificación de procesos se implementó mediante el algoritmo Round Robin (RR) con quantum configurable. Round Robin fue seleccionado deliberadamente por su capacidad demostrada para repartir el tiempo de CPU de forma equitativa entre procesos listos y por su relativa facilidad de análisis y comprensión. En el simulador, cada proceso está representado por una estructura de datos PCB (Process Control Block) que contiene: identificador único (pid), nombre descriptivo del proceso, tiempo de ráfaga estimado o proporcionado, tiempo restante de ejecución, estado actual (New, Ready, Running, Blocked, Terminated), y referencias a recursos asignados como base de dirección de memoria y lista de archivos abiertos.

El scheduler (planificador) expone métodos públicos para: encolar procesos nuevos en el estado Ready, seleccionar el siguiente proceso a ejecutar basándose en la política Round Robin, simular la ejecución de un proceso por un segmento de tiempo (quantum) especificado, procesar cambios de estado y generar volcados de estado (dumps) del estado interno del scheduler. Como consecuencia directa de esta implementación, los experimentos realizados permiten medir métricas temporales precisas como tiempo de turnaround total, tiempo promedio de respuesta, número de contextos de cambio de proceso y uso efectivo del CPU.

El quantum es un parámetro configurable que afecta dramáticamente el comportamiento global del sistema. Un quantum pequeño (por ejemplo, 5 unidades de tiempo) produce más cambios de contexto pero respuestas más rápidas para procesos interactivos cortos. Un quantum grande reduce el overhead de cambio pero puede causar que procesos interactivos sufran latencias inaceptables.

\subsection{Gestión de Memoria: First Fit con Coalescencia}

La gestión de memoria utiliza el algoritmo First Fit aplicado sobre una representación estrictamente contigua de la memoria principal. La estructura de memoria se implementa como una lista ordenada de bloques (MemoryBlock), cada uno con los campos específicos: dirección inicial (en la memoria simulada), tamaño (en unidades de memoria), bandera booleana indicando si está libre, y pid del proceso ocupante cuando está asignado.

Al solicitar memoria de tamaño S desde un proceso con pid P, el algoritmo recorre linealmente los bloques buscando el primer hueco libre que tenga tamaño suficiente (es decir, tamaño >= S). Si se encuentra, se asigna y se actualiza la estructura de lista. Cuando el tamaño del hueco encontrado es mayor que S, el algoritmo divide el hueco en dos bloques: uno asignado de tamaño exacto S y otro libre con el tamaño restante (tamaño\_hueco - S).

Al liberar memoria de un proceso, se marca el bloque correspondiente como libre. Inmediatamente después se intenta ejecutar una operación de coalescencia, que detecta si el bloque recién liberado es adyacente a otro bloque libre (puede ser al inicio o al final). Si es así, se fusionan en un único bloque más grande. Esta operación de coalescencia es crítica para mitigar fragmentación externa cuando se tienen patrones de asignación y liberación intercalados. Sin coalescencia, la fragmentación aumentaría rápidamente.

El algoritmo First Fit fue elegido deliberadamente por su simplicidad intrínseca y por su utilidad didáctica inmediata: ilustra de forma directa y observable la fragmentación externa y permite experimentar con patrones de asignación que demuestran claramente las limitaciones fundamentales de este método. Aunque existen algoritmos más sofisticados como Best Fit o Buddy Allocator, First Fit es más fácil de entender, de implementar correctamente y de instrumentar para visualización.

\subsection{Sistema de Archivos: Asignación Contigua de Bloques}

El sistema de archivos implementado usa asignación contigua de bloques de disco. Cada archivo se representa mediante una estructura FCB (File Control Block) que registra: nombre del archivo, bloque inicial de disco, tamaño en bloques, lista de pids que lo tienen actualmente abierto. El disco simulado se modela como una lista de bloques, cada uno con metadatos de estado que facilitan la visualización y control.

La elección de asignación contigua simplifica drásticamente el cálculo de direcciones dentro del archivo durante lecturas y escrituras, facilitando la implementación del código en un simulador educativo. Sin embargo, la asignación contigua también evidencia rápidamente y de manera observable problemas de fragmentación de disco: tras sucesivas operaciones de creación y eliminación de archivos de tamaños variados, el espacio disco simulado queda fragmentado en numerosos huecos pequeños dispersos, dificultando la creación de archivos grandes a pesar de existir espacio total disponible. Estos efectos son precisamente los que se busca observar en el contexto de un proyecto pedagógico.

\subsection{Entrada/Salida: Colas FIFO por Dispositivo}

Las operaciones de E/S se modelan mediante colas FIFO independientes por dispositivo. Cada dispositivo mantiene una cola de espera donde se encolan estructuras IORequest que contienen: identificador del proceso solicitante, tipo de operación (lectura, escritura, etc.), dispositivo objetivo, y longitud de datos de la operación. El simulador procesa las colas de forma secuencial, y al completar una operación se simula una interrupción que reactivará al proceso que estaba bloqueado esperando el resultado.

El modelo FIFO es intencionalmente simple: su uso permite centrarse en el efecto de las operaciones de E/S sobre la planificación de procesos y evitar complejidades extra que distraerían del objetivo educativo. En un sistema operativo real, las colas de dispositivos pueden tener políticas más complejas, pero para fines de educación y pedagogía, FIFO es suficiente, aclaratorio y directo.

\section{Estructuras de Datos y Modelos de Dominio}

Las estructuras de datos fueron diseñadas con los criterios de ser compactas, explícitas y fácilmente inspeccionables. El uso de tipos simples y estructuras claras facilita la comprensión, permite la instrumentación del código para volcado de estado y simplifica las pruebas de validación.

El PCB (Process Control Block) almacena la información esencial de cada proceso: identificador único (pid), nombre legible del proceso, tiempo de ráfaga original estimado, tiempo restante de ejecución, estado actual (New, Ready, Running, Blocked, Terminated), referencias a recursos asignados como dirección base de memoria y lista de descriptores de archivos abiertos. Además, mantiene campos auxiliares para métricas: tiempo de llegada al sistema, tiempo de finalización de ejecución, número de veces que ha sido preempted. Estos campos son críticos para poder calcular estadísticas después de la ejecución de escenarios completos.

El MemoryBlock contiene los siguientes campos: dirección inicial (dirección simulada en la memoria), tamaño en unidades de memoria, bandera booleana libre, y pid ocupante cuando está asignado. La lista ordenada de MemoryBlock conforma el MemoryMap completo. Al liberar bloques, se implementa la operación de coalescencia que detecta bloques adyacentes libres y los une para formar un bloque mayor. Esta operación es importante para mitigar fragmentación en patrones específicos donde las liberaciones ocurren secuencialmente.

Para el sistema de archivos, cada archivo se representa con un FCB que incluye: nombre único del archivo, tamaño actual en bloques, bloque inicial de disco, y una lista opcional de pids que lo tienen actualmente abierto. El disco simulado se modela como una lista de BlockFS, donde cada uno contiene: bloque de inicio, tamaño, bandera de libre, y nombre de archivo si está ocupado.

Las solicitudes de E/S se modelan con una estructura IORequest que contiene: pid del proceso solicitante, tipo de dispositivo (disco, impresora, etc.), tipo de operación (lectura, escritura), y longitud de datos de la operación. Las colas por dispositivo son simplemente listas FIFO de IORequest, y cada dispositivo tiene un DeviceEntry que incluye: nombre legible del dispositivo, estado actual (ocupado/libre), longitud de cola, y la cola FIFO de solicitudes pendientes.

\section{Implementación Detallada y Organización del Código}

El proyecto está implementado en C++17, lenguaje elegido por su balance entre rendimiento, claridad de expresión, y disponibilidad amplia de herramientas. Utiliza CMake como sistema de construcción, facilitando compatibilidad en distintos entornos (Windows, Linux, macOS).

La organización del código sigue fielmente la separación por capas arquitectónicas ya descrita: carpeta \texttt{domain} contiene entidades de dominio y puertos; \texttt{application} contiene casos de uso y orquestadores; \texttt{adapters/outbound} contiene implementaciones de puertos; \texttt{adapters/inbound} contiene runners y CLI.

Cada adaptador implementa una interfaz bien definida: por ejemplo, la interfaz de memoria expone métodos como \texttt{allocate(pid, size)}, \texttt{free(pid)}, \texttt{canAllocate(size)}, y \texttt{dump()}. Los planificadores implementan \texttt{addProcess(PCB)}, \texttt{runQuantum()}, \texttt{getCurrentProcess()}, y \texttt{dumpState()}.

\section{Estrategia Comprehensiva de Pruebas}

La estrategia de pruebas se diseñó para cubrir tanto unidades individuales como integraciones complejas. Los tests unitarios verifican comportamiento de adaptadores aislados: asignación y liberación en memoria, operaciones del sistema de archivos y ejecución de planificadores. Los tests de integración combinan módulos para validar escenarios reales: CPU+memoria, E/S concurrente y flujos completos.

Los tests están registrados en CMake e invocables con CTest. Se recomienda ejecutar con \texttt{ctest -C Release --output-on-failure} para obtener detalles cuando fallan.

\section{Resultados y Análisis Experimental}

En pruebas de Round Robin con quantum pequeño (5 unidades), observamos incremento significativo de cambios de contexto pero reducción de tiempo de respuesta para procesos cortos. Con quantum grande, observamos lo opuesto. Estos resultados coinciden con la literatura académica.

En pruebas de First Fit, series de asignaciones y liberaciones generan fragmentación visible. En escenarios con patrones alternados de asignaciones grandes/pequeñas y liberaciones, la memoria queda fragmentada en huecos dispersos. Mediciones mostraron fragmentación hasta 40-50 por ciento en cargas pesadas.

En sistema de archivos con asignación contigua, creación repetida de archivos variados causa discontinuidades. Archivos grandes se tornan imposibles de crear con el tiempo sin compactación.

En E/S, colas FIFO preservan orden. Latencia promedio crece proporcionalmente a longitud de cola, comportamiento esperado.

\section{Limitaciones Deliberadas y Consideraciones}

El simulador presenta limitaciones deliberadas por motivos pedagógicos. Memoria es estrictamente contigua sin paginación. Sistema de archivos usa asignación contigua sin compactación. Modelo de E/S es simplificado con FIFO. No hay mecanismos de protección ni aislamiento real entre procesos.

Finalmente, el simulador está diseñado para educación y no es producción. Su objetivo es pedagógico.

\section{Recomendaciones para Extensiones Futuras}

Se enumeran extensiones que agregan valor:

1) Implementar Best Fit y Worst Fit como adaptadores alternativos de memoria.

2) Implementar Buddy Allocator que divide memoria recursivamente.

3) Añadir soporte para paginación con tabla de páginas.

4) Extender sistema de archivos con asignación enlazada o inodos jerárquicos.

5) Implementar E/S con prioridades dinámicas o colas multi-nivel.

6) Desarrollar interfaz gráfica web ligera para visualización en tiempo real.

7) Implementar algoritmos de scheduling alternativos (SJF, Priority Scheduling, MLFQ).

8) Agregar sincronización primitiva como semáforos y mutexes.

Cada extensión puede implementarse como adaptador alternativo aprovechando arquitectura hexagonal.

\section{Guía de Compilación y Ejecución}

Para compilar en Windows con CMake:

\begin{verbatim}
cd cpp_os_simulator
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build --config Release
\end{verbatim}

Para ejecutar tests:

\begin{verbatim}
cd build
ctest -C Release --output-on-failure
\end{verbatim}

Para ejecutar demos:

\begin{verbatim}
./build/Release/memory_cli
./build/Release/files_cli
./build/Release/kernel_runner
\end{verbatim}

\section{Conclusiones Comprehensivas y Reflexiones Finales}

\subsection{Logros y Objetivos Alcanzados}

El proyecto "Mini-Kernel" ha cumplido exitosamente con todos los objetivos primarios establecidos al inicio del desarrollo. Se ha creado una plataforma práctica, extensible y altamente efectiva para el estudio, comprensión y experimentación con conceptos fundamentales de sistemas operativos en un ambiente académico controlado. Las decisiones de diseño arquitectónico (arquitectura hexagonal), algorítmicas (Round Robin, First Fit, asignación contigua, colas FIFO) y estructurales se eligieron meticulosamente para maximizar la claridad pedagógica sin sacrificar la fidelidad conceptual, permitiendo experimentación controlada bajo condiciones reproducibles.

El simulador integra de manera cohesiva cuatro subsistemas principales que interactúan dinámicamente: planificación de procesos, gestión de memoria, sistemas de archivos y dispositivos de entrada/salida. Esta integración es crítica porque permite que estudiantes observen cómo decisiones en un subsistema afectan el comportamiento global del sistema. Por ejemplo, un quantum de planificación pequeño afecta directamente la fragmentación de memoria porque aumenta el número de cambios de contexto y patrones de asignación/liberación. De manera similar, saturación en las colas de E/S afecta métricas de turnaround en la planificación porque procesos se bloquean esperando operaciones de disco.

\subsection{Contribuciones Técnicas y Pedagógicas}

Las contribuciones técnicas principales del proyecto incluyen: primero, la implementación de una arquitectura hexagonal completa y funcional que demuestra claramente cómo separar dominio de adaptadores, facilitando tanto testing como extensibilidad. Segundo, la instrumentación comprehensiva del simulador que permite observar y medir fenómenos esenciales de sistemas operativos como fragmentación, latencias, cambios de contexto y tiempos de respuesta. Tercero, la creación de una suite extensiva de tests unitarios e integración que valida correctamente el comportamiento de cada componente y sus interacciones.

Las contribuciones pedagógicas son igualmente significativas. El simulador permite que estudiantes experimenten directamente conceptos que normalmente solo se entienden teóricamente: pueden variar el quantum y observar inmediatamente cómo cambian métricas de fairness y latencia; pueden ejecutar patrones de asignación y liberación y ver cómo emerge la fragmentación; pueden generar cargas de E/S y medir cómo colas afectan tiempos globales. Esta capacidad de experimentación controlada es invaluable en educación de sistemas operativos.

Además, la documentación extensiva y los ejemplos proporcionados sirven como referencia para estudiantes y docentes. Los algoritmos están explicados con suficiente detalle para que un estudiante entienda no solo qué hacen, sino por qué se eligieron y qué trade-offs representan.

\subsection{Validación Experimental y Confirmación de Hipótesis}

Los resultados de prueba extensos confirman comportamientos esperados según la teoría académica de sistemas operativos. Observamos que Round Robin con quantum pequeño efectivamente reduce tiempo de respuesta para procesos cortos a costa de mayor overhead de cambio de contexto. Esto coincide perfectamente con la literatura y permite a estudiantes cuantificar este trade-off.

Observamos que First Fit genera fragmentación externa visible y cuantificable en escenarios con patrones de asignación variados. Fragmentación llegó a alcanzar 40-50 por ciento de la memoria en escenarios de carga pesada, demostrando dramáticamente las limitaciones de este algoritmo. Sin embargo, coalescencia demostró ser efectiva en ciertos patrones, reduciendo fragmentación cuando liberaciones son secuenciales.

La asignación contigua en sistema de archivos mostró exactamente las limitaciones esperadas: tras crear y eliminar archivos de tamaños variados, el disco simulado queda fragmentado, dificultando creación de archivos grandes. Este fenómeno es observable incluso en escenarios pequeños, lo que facilita la comprensión de por qué sistemas operativos reales necesitan esquemas más sofisticados.

Las colas FIFO para E/S preservaron orden de llegada y mostraron que latencia promedio crece linealmente con longitud de cola, comportamiento teóricamente esperado y empíricamente validado.

\subsection{Valor Pedagógico Demostrado}

El valor pedagógico del proyecto es demostrable y directo. Estudiantes que trabajan con el simulador pueden:

\begin{itemize}
\item Visualizar dinámicamente estados de procesos, memoria y dispositivos, facilitando comprensión visceral de conceptos abstractos.
\item Ejecutar experimentos reproducibles, variando parámetros y observando efectos con precisión.
\item Implementar extensiones (nuevos algoritmos) dentro de la arquitectura existente, aprendiendo buenas prácticas de diseño.
\item Comparar algoritmos bajo condiciones exactamente iguales, facilitando comprensión de trade-offs.
\item Generar datos de experimentos (tiempos, fragmentación, etc.) para análisis y reportes académicos.
\end{itemize}

Estos usos demuestran que el simulador es efectivo tanto para enseñanza pasiva (observación) como activa (experimentación y extensión).

\subsection{Arquitectura Hexagonal como Decisión Estratégica}

La elección de arquitectura hexagonal fue estratégica y acertada. Esta arquitectura:

\begin{itemize}
\item Permitió separación clara entre dominio e implementaciones, facilitando testing riguroso sin dependencias externas.
\item Facilitó intercambio de algoritmos: cambiar de Round Robin a Priority Scheduling requiere solo cambiar un adaptador.
\item Permitió crecimiento del proyecto de manera disciplinada: nuevas características se agregan como adaptadores sin disruption.
\item Facilita colaboración: desarrolladores pueden trabajar en adaptadores independientes sin conflictos.
\item Simplificó validación: puertos definen contratos claros que simplifican testing.
\end{itemize}

Esta decisión arquitectónica es una de las fortalezas principales del proyecto y lo diferencia de simuladores más monolíticos.

\subsection{Limitaciones Reconocidas y Aceptadas}

Es importante reconocer explícitamente que el simulador, por diseño pedagógico, presenta limitaciones deliberadas:

La memoria es estrictamente contigua sin paginación ni memoria virtual, simplificando el modelo pero limitando su capacidad de demostrar esquemas modernos. Sistema de archivos usa asignación contigua sin compactación automática, evidenciando limitaciones pero sin resolver la fragmentación. Modelo de E/S es simplificado con FIFO sin prioridades dinámicas o políticas sofisticadas. No hay mecanismos de protección, privilegios o aislamiento real entre procesos. No hay sincronización primitiva como semáforos o mutexes.

Estas limitaciones no son deficiencias sino decisiones conscientes para mantener el simulador comprehensible y enfocado en conceptos esenciales. Un simulador que intentara replicar cada complejidad de un kernel real sería incomprehensible para propósitos pedagógicos.

\subsection{Extensibilidad y Camino a Futuro}

La arquitectura del proyecto es extensible de manera natural. Se han enumerado ocho extensiones potenciales de complejidad gradualmente creciente, desde implementar algoritmos alternativos de memoria hasta agregar paginación, sincronización y interfaz gráfica. Cada extensión aprovecha la arquitectura hexagonal y puede implementarse sin modificar el núcleo.

Particularmente prometedoras son:

\begin{itemize}
\item Implementación de Best Fit y Buddy Allocator, permitiendo comparación empírica directa de algoritmos.
\item Soporte para paginación simple, demostrando ventajas de memoria virtual sobre asignación contigua.
\item Algoritmos de scheduling alternativos (SJF, Priority Scheduling, MLFQ), demostrando espectro de trade-offs.
\item Interfaz gráfica que muestre estado en tiempo real, mejorando significativamente la experiencia pedagógica.
\end{itemize}

Estas extensiones son viables con esfuerzo razonable debido a la arquitectura.

\subsection{Impacto en Enseñanza e Investigación}

El simulador tiene potencial de impacto significativo en enseñanza de sistemas operativos:

\begin{itemize}
\item Para docentes: herramienta para demostraciones interactivas en clase, facilitando enseñanza de conceptos complejos.
\item Para estudiantes: entorno de experimentación que completa la teoría con práctica controlada.
\item Para investigadores: plataforma para estudios comparativos de políticas y algoritmos.
\item Para la comunidad académica: contribución open-source que puede ser adoptada en otros programas.
\end{itemize}

La disponibilidad en GitHub, con documentación extensiva y código limpio, facilita su adopción y extensión por terceros.

\subsection{Reflexión sobre el Proceso de Desarrollo}

El proceso de desarrollo fue iterativo y respondió bien a decisiones de diseño justificadas. Las elecciones de usar arquitectura hexagonal, C++17 con CMake, y algoritmos pedagógicamente claros resultaron acertadas. La instrumentación cuidadosa para volcado de estado fue crítica para permitir visualización y debugging. La suite comprehensiva de tests aseguró que cambios posteriores no rompieran funcionalidad existente.

El proyecto demuestra que es posible crear un simulador completo y educativamente valioso sin complejidad excesiva ni dependencias pesadas. El código está diseñado para ser legible y mantenible, facilitando tanto su uso como su extensión.

\subsection{Conclusión General}

En conclusión, el proyecto Mini-Kernel ha cumplido su propósito fundamental: crear una plataforma efectiva, extensible y pedagógicamente valiosa para el estudio de sistemas operativos. La arquitectura hexagonal adoptada permite separación clara y extensibilidad. Los algoritmos seleccionados ejemplifican conceptos esenciales sin complejidad innecesaria. La instrumentación permite observación y medición de fenómenos importantes. Los tests validan correctitud. La documentación facilita adopción y extensión.

El simulador es inmediatamente útil en educación, proporciona una base sólida para investigación comparativa, y está posicionado para extensión futura con características más sofisticadas. La calidad de la arquitectura sugiere que este proyecto tiene longevidad y potencial de evolución significativa.

Finalmente, el Mini-Kernel representa una contribución valiosa a los recursos pedagógicos disponibles para la enseñanza de sistemas operativos, siendo simultáneamente accesible a estudiantes principiantes y extensible por investigadores avanzados. Su disponibilidad open-source en GitHub lo hace potencialmente adoptable por múltiples instituciones académicas, multiplicando su impacto pedagógico más allá del contexto original de desarrollo.

\begin{thebibliography}{00}
\bibitem{b1} Silberschatz, A., Galvin, P. B., \& Gagne, G. (2018). Operating System Concepts (10th ed.). Wiley.
\bibitem{b2} GeeksforGeeks. "Round-Robin Scheduling in Operating System". https://www.geeksforgeeks.org/operating-systems/round-robin-scheduling-in-operating-system/
\bibitem{b3} GeeksforGeeks. "First-Fit Allocation in Operating Systems". https://www.geeksforgeeks.org/operating-systems/first-fit-allocation-in-operating-systems/
\bibitem{b4} takeUforward. "Contiguous Allocation, Paging and Segmentation." https://takeuforward.org/operating-system/contiguous-allocation-paging-segmentation
\bibitem{b5} GeeksforGeeks. "FIFO". https://www.geeksforgeeks.org/dsa/introduction-to-queue-data-structure-and-algorithm-tutorials/
\bibitem{b6} Cockburn, A. (2005). "Hexagonal Architecture". https://alistair.cockburn.us/hexagonal-architecture/
\bibitem{b7} Martin, R. C. (2008). Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall.
\end{thebibliography}

\end{document}
